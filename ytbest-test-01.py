import streamlit as st
from googleapiclient.discovery import build
from googletrans import Translator
import re
from collections import Counter
from datetime import datetime, timedelta
import statistics
import random
import time
import textwrap

# --- [ì„¤ì •] ê¸°ë³¸ ì •ë³´ ---
YOUTUBE_API_SERVICE_NAME = "youtube"
YOUTUBE_API_VERSION = "v3"

st.set_page_config(page_title="Team SENA: Trend Intelligence", layout="wide")

# CSS ë””ìì¸
st.markdown("""
<style>
    .video-card { background-color: #ffffff; padding: 18px; border-radius: 12px; border: 1px solid #e0e0e0; margin-bottom: 25px; box-shadow: 0 4px 12px rgba(0,0,0,0.06); display: flex; flex-direction: column; height: 100%; }
    .thumb-link img { transition: transform 0.2s; border-radius: 8px; width: 100%; aspect-ratio: 16/9; object-fit: cover; }
    .thumb-link img:hover { transform: scale(1.02); }
    .v-title { font-size: 0.95rem; font-weight: 800; color: #111; line-height: 1.4; max-height: 2.8em; overflow: hidden; margin: 10px 0 5px 0; }
    .v-meta { font-size: 0.82rem; color: #555; margin-bottom: 5px; line-height: 1.4; padding-bottom: 5px; border-bottom: 1px dashed #eee; }
    .v-status { display: inline-block; padding: 3px 7px; border-radius: 4px; font-size: 0.7rem; font-weight: bold; margin-bottom: 5px; }
    .status-hot { background-color: #ffebee; color: #c62828; }
    .status-steady { background-color: #e3f2fd; color: #1565c0; }
    .v-insight-box { background-color: #f8f9fa; padding: 12px; border-radius: 8px; font-size: 0.82rem; border-left: 4px solid #1a73e8; margin-top: 5px; }
    .report-container { background-color: #1a1c1e; color: #e1e1e1; padding: 35px; border-radius: 20px; margin-top: 40px; border: 2px solid #ff4b4b; }
    .report-header { font-size: 1.7rem; font-weight: 900; color: #ff4b4b; border-bottom: 2px solid #ff4b4b; padding-bottom: 10px; margin-bottom: 25px; }
    .section-title { font-size: 1.2rem; font-weight: bold; color: #ffeb3b; margin-top: 25px; margin-bottom: 12px; }
    .section-content { background: #25282c; padding: 18px; border-radius: 12px; line-height: 1.8; font-size: 0.95rem; color: #eee; border: 1px solid #333; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“¡ ê¸€ë¡œë²Œ íŠ¸ë Œë“œ ì¸í…”ë¦¬ì „ìŠ¤ (SENA)")

translator = Translator()

# --- [ì‚¬ì´ë“œë°” ìƒë‹¨: API í‚¤ ì…ë ¥ ì¹¸] ---
st.sidebar.header("ğŸ”‘ API ì„¤ì •")
user_api_key = st.sidebar.text_input(
    "YouTube API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
    type="password", 
    help="Google Cloud Consoleì—ì„œ ë°œê¸‰ë°›ì€ YouTube Data API v3 í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
)

if not user_api_key:
    st.sidebar.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.info("ğŸ‘ˆ ì™¼ìª½ ë©”ë‰´ì— YouTube API í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. (ë°œê¸‰ ë°©ë²•ì€ ë„ì›€ë§ ì°¸ì¡°)")
    st.stop() # í‚¤ê°€ ì—†ìœ¼ë©´ ì•± ì‹¤í–‰ ì¤‘ë‹¨

# --- ê³µí†µ í•¨ìˆ˜ ---
def get_youtube_client(api_key):
    return build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=api_key)

def parse_duration(duration):
    minutes = re.search(r'(\d+)M', duration)
    seconds = re.search(r'(\d+)S', duration)
    total = 0
    if minutes: total += int(minutes.group(1)) * 60
    if seconds: total += int(seconds.group(1))
    return total

def is_japanese(text):
    return bool(re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', text))

def is_strictly_non_us(title, channel):
    scripts = [re.compile(r'[\u0900-\u097F]+'), re.compile(r'[\u0E00-\u0E7F]+'), re.compile(r'[\u0600-\u06FF]+')]
    combined = title + " " + channel
    if any(s.search(combined) for s in scripts): return True
    blacklist = ['india', 'hindi', 'bollywood', 't-series', 'zeemusic']
    return any(k in combined.lower() for k in blacklist)

def calculate_v_point(views, likes, comments):
    if views == 0: return 0
    return int((views * 0.001) * (1 + (likes/views*10) + (comments/views*50)))

def generate_sena_report(region_name, video_type, results, keywords):
    if not results: return ""
    avg_views = statistics.mean([v['view_raw'] for v in results])
    avg_viral = statistics.mean([v['v_point'] for v in results])
    top_k = [k for k, c in Counter(keywords).most_common(3)]
    k_str = ", ".join(top_k)
    
    return f"""
<div class="report-container">
<div class="report-header">ğŸš© ì„¸ë‚˜ íŒ€ì¥ì˜ í˜„ì¥í˜• ì‹¤í–‰ ë¦¬í¬íŠ¸</div>
<div style="font-size: 0.9rem; color: #888; margin-bottom: 20px;">2026 {region_name} {video_type} ì‹œì¥ | ì‚¬ìš©ì API ë°ì´í„° ê¸°ë°˜ ë¶„ì„</div>
<div class="section-title">ğŸ“Š 1. [ë°ì´í„° ì¶”ì¶œ] í•µì‹¬ ì§€í‘œ ìš”ì•½</div>
<div class="section-content">
ì, ì…ë ¥í•œ í‚¤ë¡œ ë½‘ì•„ì˜¨ ë°ì´í„°ì•¼. ì§€ê¸ˆ ì´ ë°”ë‹¥ ë¶„ìœ„ê¸° íŒŒì•…ìš© í•µì‹¬ ìˆ«ìë“¤ í™•ì¸í•´ë´.
<table>
<tr><th>í‰ê·  ì¡°íšŒìˆ˜</th><th>í‰ê·  Viral Point</th><th>í•µì‹¬ DNA</th></tr>
<tr><td>{int(avg_views):,}íšŒ</td><td>{int(avg_viral):,}ì </td><td>{k_str}</td></tr>
</table>
íŠ¹íˆ Viral Point íŠ€ëŠ” ì• ë“¤ì€ ì¡°íšŒìˆ˜ë³´ë‹¤ <b>ëŒ“ê¸€ ë°˜ì‘</b>ì´ ì••ë„ì ì´ë¼ëŠ” ê±° ë³´ì´ì§€?
</div>
<div class="section-title">ğŸ—¨ï¸ 2. [ì‹œì²­ì ë°˜ì‘ ì˜ˆì¸¡] ì™œ ëŒ“ê¸€ ì „ìŸí„°ê°€ ëì„ê¹Œ?</div>
<div class="section-content">
ì‹œì²­ìë“¤ì€ ì§€ê¸ˆ <b>"{top_k[0] if top_k else 'ì´ ì£¼ì œ'}"</b>ì— ëŒ€í•´ ë‹¨ìˆœíˆ ë³´ëŠ” ê²Œ ì•„ë‹ˆë¼ <b>'ìê¸° ì–˜ê¸°'</b>ë¼ê³  ëŠê»´ì„œ í‚¤ë³´ë“œë¥¼ ì¡ê³  ìˆì–´. 
ìƒìœ„ê¶Œ ì˜ìƒë“¤ì€ ì „ë¶€ <b>'ê³µê°'</b> ì•„ë‹ˆë©´ <b>'ë¹„êµ'</b>ë¥¼ ê±´ë“œë ¤ì„œ "ë„ˆëŠ” ì–´ë•Œ?"ë¼ê³  ë¬»ëŠ” ì—°ì¶œì´ íŠ¹ì§•ì´ì•¼.
</div>
<div style="margin-top:30px; text-align:center; font-weight:bold; color:#ff4b4b; border:1px solid #ff4b4b; padding:15px; border-radius:10px;">
ğŸ’¡ íŒ€ì¥ ì„¸ë‚˜ì˜ í•œ ì¤„ í‰: "ë°ì´í„°ëŠ” ì •ì§í•´. {top_k[0] if top_k else 'í‚¤ì›Œë“œ'}ë¡œ ì‚¬ëŒë“¤ ë°˜ì‘ ëŒì–´ë‚¼ ê¸°íšë¶€í„° ë‹¤ì‹œ ê³ ë¯¼í•´ë´!"
</div>
</div>
"""

def fetch_videos(api_key, topic_text, v_type, r_info, v_count):
    youtube = get_youtube_client(api_key)
    is_shorts = "Shorts" in v_type
    is_popular_mode = not topic_text.strip()
    collected, next_token = [], None
    for _ in range(8):
        try:
            if not is_popular_mode:
                try: trans_q = translator.translate(topic_text, dest=r_info['lang']).text
                except: trans_q = topic_text
                req = youtube.search().list(part="snippet", q=f"{trans_q} {'#shorts' if is_shorts else ''}", type="video", videoDuration="short" if is_shorts else "any", regionCode=r_info['code'], relevanceLanguage=r_info['lang'], order="viewCount", maxResults=50, pageToken=next_token)
            else:
                if is_shorts:
                    req = youtube.search().list(part="snippet", q=f"#shorts", type="video", videoDuration="short", regionCode=r_info['code'], relevanceLanguage=r_info['lang'], order="viewCount", maxResults=50, pageToken=next_token)
                else:
                    req = youtube.videos().list(part="snippet,statistics", chart="mostPopular", regionCode=r_info['code'], maxResults=50, pageToken=next_token)
            res = req.execute()
            collected.extend(res.get('items', []))
            next_token = res.get('nextPageToken')
            if not next_token or len(collected) >= 400: break
        except Exception as e:
            raise e

    v_ids = []
    for i in collected:
        if 'id' in i:
            vid = i['id']['videoId'] if isinstance(i['id'], dict) and 'videoId' in i['id'] else i['id']
            v_ids.append(vid)

    if not v_ids: return [], 0, ""
    all_stats = []
    for i in range(0, len(v_ids), 50):
        chunk = v_ids[i:i+50]
        stats = youtube.videos().list(part="snippet,statistics,contentDetails", id=",".join(chunk)).execute()
        all_stats.extend(stats.get('items', []))

    results, kws, now = [], [], datetime.now()
    non_us_count, max_non_us = 0, int(v_count * 0.1)
    for i in all_stats:
        t, c = i['snippet']['title'], i['snippet']['channelTitle']
        d_sec = parse_duration(i['contentDetails']['duration'])
        p_date = datetime.strptime(i['snippet']['publishedAt'], "%Y-%m-%dT%H:%M:%SZ")
        days = (now - p_date).days
        if days > 365 or (not is_shorts and d_sec < 120) or (is_shorts and d_sec > 120): continue
        if r_info['code'] == 'JP' and not is_japanese(t + c): continue
        if r_info['code'] == 'US' and is_strictly_non_us(t, c):
            if non_us_count >= max_non_us: continue
            non_us_count += 1
        v = int(i['statistics'].get('viewCount', 0))
        l = int(i['statistics'].get('likeCount', 0)) if 'likeCount' in i['statistics'] else 0
        cm = int(i['statistics'].get('commentCount', 0)) if 'commentCount' in i['statistics'] else 0
        if days > 30 and (v < 500000 or (l+cm)/v < 0.02): continue
        vp = calculate_v_point(v, l, cm)
        tier = 1 if days <= 10 else (2 if days <= 30 else 3)
        kws.extend([w for w in re.sub(r'[^\w\s]', '', t).split() if len(w) > 1])
        results.append({
            'title': t, 'thumbnail': i['snippet']['thumbnails']['high']['url'],
            'url': f"https://www.youtube.com/shorts/{i['id']}" if is_shorts else f"https://www.youtube.com/watch?v={i['id']}",
            'channel': c, 'view_count': v, 'date': i['snippet']['publishedAt'][:10],
            'v_point': vp, 'status': "ğŸ”¥ ì´ˆì‹ ì„±" if tier==1 else "ğŸ”„ ìŠ¤í…Œë””", 'tier': tier, 'view_raw': v
        })
    results.sort(key=lambda x: (x['tier'], -x['v_point']))
    final = results[:v_count]
    report = generate_sena_report(r_info['code'], "Shorts" if is_shorts else "Long-form", final, kws)
    return final, (len(final)/v_count)*100 if v_count > 0 else 0, report

# --- ì‚¬ì´ë“œë°” ë©”ë‰´ ---
st.sidebar.header("ğŸ“Š ë¶„ì„ íŒŒë¼ë¯¸í„°")
region_map = {"í•œêµ­ ğŸ‡°ğŸ‡·": {"code": "KR", "lang": "ko"}, "ë¯¸êµ­ ğŸ‡ºğŸ‡¸": {"code": "US", "lang": "en"}, "ì¼ë³¸ ğŸ‡¯ğŸ‡µ": {"code": "JP", "lang": "ja"} }
region_name = st.sidebar.selectbox("ğŸ“ íƒ€ê²Ÿ ì‹œì¥", list(region_map.keys()))
sel_region = region_map[region_name]
video_type = st.sidebar.radio("ğŸ“± ì½˜í…ì¸  í¬ë§·", ["ë¡±í¼ (2ë¶„ ì´ìƒ)", "ìˆí¼ (Shorts)"])
count = st.sidebar.slider("ğŸ”¢ ë¶„ì„ ìƒ˜í”Œ", 1, 30, 8)
topic = st.sidebar.text_input("ğŸ” í‚¤ì›Œë“œ/ì£¼ì œ", placeholder="ê³µë€: êµ­ê°€ë³„ íŠ¸ë Œë“œ ìˆ˜ì§‘")
search_clicked = st.sidebar.button("ğŸš€ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì‹œì‘", use_container_width=True)

# --- ê²°ê³¼ ì¶œë ¥ ---
if search_clicked or not topic:
    with st.spinner('ì‚¬ìš©ì APIë¡œ ë°ì´í„°ë¥¼ ë”¥ ìŠ¤ìº” ì¤‘...'):
        try:
            final_res, acc, report = fetch_videos(user_api_key, topic, video_type, sel_region, count)
            st.subheader(f"ğŸ“ {region_name} {video_type} ë¶„ì„ ê²°ê³¼")
            if not final_res: st.warning("ë°ì´í„°ë¥¼ í™•ë³´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                grid = st.columns(4)
                for idx, v in enumerate(final_res):
                    with grid[idx % 4]:
                        s_class = "status-hot" if v['tier'] == 1 else "status-steady"
                        st.markdown(f"""
                        <div class="video-card">
                            <a href="{v['url']}" target="_blank" class="thumb-link"><img src="{v['thumbnail']}"></a>
                            <div style="margin-top:10px;"><span class="v-status {s_class}">{v['status']}</span></div>
                            <div class="v-title">{v['title']}</div>
                            <div class="v-meta"><b>{v['channel']}</b><br>ì¡°íšŒìˆ˜: {v['view_count']:,}íšŒ<br>ê³µê°œì¼: {v['date']}</div>
                            <div class="v-insight-box">ğŸŒ <b>Viral Point:</b> <span style="color:#1a73e8; font-weight:800;">{v['v_point']:,}</span></div>
                        </div>
                        """, unsafe_allow_html=True)
                st.markdown(report, unsafe_allow_html=True)
        except Exception as e:
            if "quotaExceeded" in str(e):
                st.error("ğŸš¨ ì…ë ¥í•˜ì‹  API í‚¤ì˜ í•˜ë£¨ í• ë‹¹ëŸ‰ì´ ëª¨ë‘ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            elif "API key not valid" in str(e):
                st.error("âŒ ì˜¬ë°”ë¥´ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤. í‚¤ ê°’ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            else:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
